{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import gradio as gr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Force Dark Mode - for the sake of my eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Google API Key exists and begins AIzaSyBR\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic and Google; comment out the Claude or Google lines if you're not using them\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Website Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of these prompts could use some work as they don't seem to exemplify some of the themes I was hoping they would achieve. The gothic_system_message's brochure is not near Edgar Allan Poe enough for my liking.\n",
    "\n",
    "system_message = \"You are an assistant that analyzes the contents of a company website landing page \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\"\n",
    "\n",
    "humorous_system_message = \"You are a witty and entertaining assistant that analyzes the contents of a \\\n",
    "company website landing page and crafts a fun, engaging brochure for prospective customers, investors, \\\n",
    "and recruits. Your responses should be humorous, lighthearted, and sprinkled with clever wordplay. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "serious_system_message = \"You are a highly professional and detail-oriented assistant that \\\n",
    "analyzes the contents of a company website landing page and produces a formal, well-structured brochure. \\\n",
    "Your tone is direct, no-nonsense, and suitable for corporate and executive-level audiences. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "gothic_system_message = \"You are a dark and mysterious assistant that analyzes the contents of a \\\n",
    "company website landing page and weaves an atmospheric, gothic-style brochure. Your tone is rich, \\\n",
    "melancholic, and poetic, invoking imagery of shadowy corridors, timeless grandeur, and the eerie \\\n",
    "passage of time. Respond in markdown.\"\n",
    "\n",
    "scientific_system_message = \"You are a precise and analytical assistant that examines the contents of a \\\n",
    "company website landing page and generates a data-driven, research-backed brochure. Your language is \\\n",
    "technical, objective, and rooted in logical reasoning, making the information accessible yet informative \\\n",
    "for scientifically-minded customers, investors, and recruits. Respond in markdown.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying Stream function to accept multiple tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt(prompt, tone=\"default\"):\n",
    "    # Dictionary mapping tones to predefined system messages\n",
    "    system_messages = {\n",
    "        \"default\": system_message,\n",
    "        \"humorous\": humorous_system_message,\n",
    "        \"serious\": serious_system_message,\n",
    "        \"gothic\": gothic_system_message,\n",
    "        \"scientific\": scientific_system_message\n",
    "    }\n",
    "\n",
    "    # Select the system message based on the chosen tone (default if not found)\n",
    "    system_message_selected = system_messages.get(tone, system_message)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message_selected},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stream GPT Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stream_gpt(prompt):\n",
    "#     messages = [\n",
    "#         {\"role\": \"system\", \"content\": system_message},\n",
    "#         {\"role\": \"user\", \"content\": prompt}\n",
    "#       ]\n",
    "#     stream = openai.chat.completions.create(\n",
    "#         model='gpt-4o-mini',\n",
    "#         messages=messages,\n",
    "#         stream=True\n",
    "#     )\n",
    "#     result = \"\"\n",
    "#     for chunk in stream:\n",
    "#         result += chunk.choices[0].delta.content or \"\"\n",
    "#         yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    # elif model==\"Claude\":\n",
    "    #     result = stream_claude(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model, tone):\n",
    "    prompt = f\"Please generate a company brochure for {company_name}. Here is their landing page:\\n\"\n",
    "    prompt += Website(url).get_contents()\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    # elif model==\"Claude\":\n",
    "    #     result = stream_claude(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company name:\"),\n",
    "        gr.Textbox(label=\"Landing page URL including http:// or https://\"),\n",
    "        gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\"),\n",
    "        gr.Dropdown([\"Default\", \"Humorous\", \"Serious\", \"Gothic\", \"Scientific\"], label=\"Select Tone\")\n",
    "    ],\n",
    "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
    "    flagging_mode=\"never\",\n",
    "    js=force_dark_mode\n",
    ")\n",
    "\n",
    "view.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company name:\"),\n",
    "        gr.Textbox(label=\"Landing page URL including http:// or https://\"),\n",
    "        gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\"),\n",
    "        gr.Dropdown([\"Default\", \"Humorous\", \"Serious\", \"Gothic\", \"Scientific\"], label=\"Select Tone\")\n",
    "    ],\n",
    "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
    "    flagging_mode=\"never\",\n",
    "    js=force_dark_mode\n",
    ")\n",
    "\n",
    "view.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
